\documentclass{article}

\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{csquotes}

\usepackage[
    backend=biber,
    style=apa,
    sortlocale=de_DE,
    natbib=true,
    url=false,
    doi=false,
    sortcites=true,
    sorting=nyt,
    isbn=false,
    hyperref=true,
    backref=false,
    giveninits=false,
    eprint=false]{biblatex}
\addbibresource{../references/bibliography.bib}

\title{Notizen zum Projekt Data Ethics}
\author{Luisa Rudin}
\date{\today}

\begin{document}
\maketitle

\abstract{
    Wie kann die Diskriminierung durch KI-Algorithmen verhindert werden und welche ethischen Maßnahmen sind notwendig?
}

\tableofcontents

\section{Einleitung}
Künstliche Intelligenz, auch abgekürzt als 'KI', ist ein von Menschen gemachter Alghorithmus.  die menschenähnliche Intelligenz und Entscheidungsfähigkeiten haben. Es handelt sich um eine Technologie, die unser Leben stark beeinflussen wird und in den vergangenen Jahren enorm mächtig geworden ist.

\section{Wie ensteht die Diskriminierung?}
Eine KI kann diskriminierend gegenüber bestimmten Personengruppen werden, wenn die Entwickler bestimmte stereotype Positionen in den Algorithmus einbauen, die zu Diskriminierung führen. Dies kann auch passieren, wenn bestimmte Variablen ausgewählt werden, die bereits diskriminierende Vorurteile enthalten. Diskriminierung kann auch während des Trainings und der Anwendung der KI entstehen, wenn nicht darauf geachtet wird, dass menschliche Voreingenommenheiten ausgeschlossen werden. Es ist wichtig, dass bei der Entwicklung von KI-Systemen darauf geachtet wird, Diskriminierung zu verhindern und alle geschützten Merkmale angemessen zu berücksichtigen.


\section{Was tut die Behörde?}
Die Antidiskriminierungsstelle des Bundes kann gegen die Diskriminierung von KI vorgehen, indem sie Menschen unterstützt, die von Diskriminierung betroffen sind, informiert, wissenschaftliche Untersuchungen durchführt und an den Deutschen Bundestag berichtet.

\section{Beispiel Amazon}
Das Beispiel von Amazon zeigt, wie ein automatisiertes Entscheidungssystem (ADM-System) dazu verwendet wurde, Bewerberinnen automatisch auszusortieren. Das System analysierte die Daten der letzten 10 Jahre und stellte fest, dass mehr Männer als Frauen bei Amazon gearbeitet haben. Basierend auf dieser Information wurden alle Bewerberinnen aussortiert, was auf eine geschlechtsspezifische Diskriminierung hindeutet. Dies verdeutlicht, wie hoch das Diskriminierungspotenzial durch algorithmische Systeme ist. Es zeigt, dass solche Systeme aufgrund von voreingenommenen Daten oder Algorithmen dazu neigen können, diskriminierende Entscheidungen zu treffen. Daher ist es wichtig, solche Systeme regelmäßig zu überprüfen und von unabhängigen Stellen testen zu lassen, um sicherzustellen, dass keine diskriminierenden Muster vorliegen.

\printbibliography

\end{document}
