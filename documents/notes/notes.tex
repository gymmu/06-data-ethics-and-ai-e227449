\documentclass{article}

\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{csquotes}

\usepackage[
    backend=biber,
    style=apa,
    sortlocale=de_DE,
    natbib=true,
    url=false,
    doi=false,
    sortcites=true,
    sorting=nyt,
    isbn=false,
    hyperref=true,
    backref=false,
    giveninits=false,
    eprint=false]{biblatex}
\addbibresource{../references/bibliography.bib}

\title{Notizen zum Projekt Data Ethics}
\author{Luisa Rudin}
\date{\today}

\begin{document}
\maketitle

\abstract{
    Wie kann die Diskriminierung durch KI-Algorithmen verhindert werden und welche ethischen Maßnahmen sind notwendig?
}

\tableofcontents

\section{Einleitung}
Künstliche Intelligenz, auch abgekürzt als 'KI', ist ein von Menschegemachtes Computerprogramm.. Es handelt sich um eine Technologie, die unser Leben stark beeinflussen wird und in den vergangenen Jahren enorm mächtig geworden ist. KI-Systeme werden durch komplexe Algorithmen trainiert, die von Personen entwickelt werden. Diese Algorithmen dienen als Schritt-für-Schritt-Anleitung, um bestimmte Aufgaben zu lösen, die menschliche Intelligenz verlangen.  Um eine KI zu trainieren, werden als Erstes Daten gesammelt. Dann wird ein Modell ausgesucht, dass der KI anweisungen gibt, was sie lernen soll. Anschliessend "füttert" man die KI mit den gesammelten Daten und anhand dessen lernt sie Zusammenhänge und Muster. Dies geschieht durch wiederholtes Testen und Anpassen der internen Parameter des Modells, bis die Vorhersagen oder Entscheidungen der KI so genau wie möglich sind. Je nach Art der Daten und der gewünschten Aufgaben können verschiedene Lernmethoden zum Einsatz kommen. Beim überwachten Lernen wird die KI mit Beispielen trainiert, bei denen die richtige Antwort bekannt ist. Beim unüberwachten Lernen versucht die KI, Muster in den Daten selbstständig zu finden. Beim bestärkenden Lernen lernt die KI durch Belohnungen und Bestrafungen, ähnlich wie ein Kind, das durch positives Feedback lernt.



\section{Wie ensteht die Diskriminierung?}
Die Diskriminierung beginnt in den Daten, die gesammelt werden um die KI zu trainieren. Den aus denen lernt der algorithmus, das eine bestimmte Personengruppe ein wiederholendes Muster in der Geschichte hat. Somit lernt die KI auch vorurteile, die von Menschen veröffentlicht wurden. Zum BEispiel: Eine KI lernt von einem Dokument, dass dunkelhäutige in der früheren Zeit benachteiligt wurden und deshalb oft kriminell waren. Also lernt die KI grob gesagt: Dunkelhäutige MEnschen sind krminell." Diese KI kann zum Beispiel für das aussortieren von Bewerbern in einem Konzern verantwortlich sein. Das führt dazu, dass er alle dunkelhäutigen Bewerber aussortiert und sie somit diskriminiert aufgrund der Daten von der sie gelernt hat. So ein ähnliches Beispiel ist tatsächlich passiert. Dazu steht unter "Beispiel Amazon" mehr. Solche diskriminierungsfälle sind shr problematisch, da immer mehr von KI gestuert wird und sie auch Entscheidungen treffen können und so viele Personen, wenn auch ohne Absicht der hersteller der KI, benachteiligt werden. 


\section{Was kann man gegen die Diskriminierung tun?}
Was die Hersteller einer KI immer machen sollten ist die daten überprüfen, mit welchen sie ihre KI trainieren.

\section{Beispiel Amazon}
Das Beispiel von Amazon zeigt, wie ein automatisiertes Entscheidungssystem (ADM-System) dazu verwendet wurde, Bewerberinnen automatisch auszusortieren. Das System analysierte die Daten der letzten 10 Jahre und stellte fest, dass mehr Männer als Frauen bei Amazon gearbeitet haben. Basierend auf dieser Information wurden alle Bewerberinnen aussortiert, was auf eine geschlechtsspezifische Diskriminierung hindeutet. Dies verdeutlicht, wie hoch das Diskriminierungspotenzial durch algorithmische Systeme ist. Es zeigt, dass solche Systeme aufgrund von voreingenommenen Daten oder Algorithmen dazu neigen können, diskriminierende Entscheidungen zu treffen. Daher ist es wichtig, solche Systeme regelmäßig zu überprüfen und von unabhängigen Stellen testen zu lassen, um sicherzustellen, dass keine diskriminierenden Muster vorliegen.

\printbibliography

\end{document}
