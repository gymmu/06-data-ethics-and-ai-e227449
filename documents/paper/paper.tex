\documentclass{article}

\usepackage{xcolor}
\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{csquotes}
\usepackage[a4paper]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{caption}

\usepackage[
    backend=biber,
    style=apa,
    sortlocale=de_DE,
    natbib=true,
    url=false,
    doi=false,
    sortcites=true,
    sorting=nyt,
    isbn=false,
    hyperref=true,
    backref=false,
    giveninits=false,
    eprint=false]{biblatex}
\addbibresource{../references/bibliography.bib}


\title{\textcolor{cyan}{Diskriminierung durch KI}}
\author{Luisa Rudin}
\date{\today}



\begin{document}

\maketitle

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{KI Diskriminierung.jpg}
    \caption{}
    \label{fig:Diskriminierung}
\end{figure}

\section{Zusammenfassung}
    \textbf{\textit{
    Wie kann die Diskriminierung durch KI-Algorithmen verhindert werden und welche ethischen Massnahmen sind notwendig?}}


\tableofcontents

\section{\textit{Einleitung}}
Künstliche Intelligenz, auch abgekürzt als 'KI', ist ein von Menschen gemachtes Computerprogramm. Es handelt sich um eine Technologie, die unser Leben stark beeinflusst und in den vergangenen Jahren enorm mächtig geworden ist. KI-Systeme werden durch komplexe Algorithmen trainiert, die von Personen entwickelt werden. Diese Algorithmen dienen als Schritt-für-Schritt-Anleitung, um bestimmte Aufgaben zu lösen, die menschliche Intelligenz verlangen.  Um eine KI zu trainieren, werden als Erstes Daten gesammelt. Dann wird ein Modell ausgesucht, dass der KI anweisungen gibt, was sie lernen soll. Anschliessend "füttert" man die KI mit den gesammelten Daten und anhand dessen lernt sie Zusammenhänge und Muster. Dies geschieht durch wiederholtes Testen und Anpassen der internen Parameter des Modells, bis die Vorhersagen oder Entscheidungen der KI so genau wie möglich sind. Je nach Art der Daten und der gewünschten Aufgaben können verschiedene Lernmethoden zum Einsatz kommen. Beim überwachten Lernen wird die KI mit Beispielen trainiert, bei denen die richtige Antwort bekannt ist. Beim unüberwachten Lernen versucht die KI, Muster in den Daten selbstständig zu finden. Beim bestärkenden Lernen lernt die KI durch Belohnungen und Bestrafungen, ähnlich wie ein Kind, das durch positives Feedback lernt.

\section{\textit{Wie entsteht die Diskriminierung?}}
Die Diskriminierung beginnt in den Daten, die gesammelt werden um die KI zu trainieren. " Die Ursachen für diese Diskriminierungen können sowohl in den verwendeten Daten, wie fehlende Repräsentativität, veraltete Daten, unzureichende Datenaufbereitung, im Algorithmus selbst, welche Parameter werden im Modell berücksichtigt, welche nicht, als auch in der Art und Weise, wie er verwendet wird: Welchen Bedarf soll das System decken und wie wird es in der Praxis angewendet? liegen.", bestätigt auch die Webseite \citep{DiskriminierendeAlgorithmen}  Denn aus denen lernt der Algorithmus, dass eine bestimmte Personengruppe ein wiederholendes Muster in der Geschichte hat. Somit lernt die KI auch Vorurteile, die von Menschen veröffentlicht wurden. Zum Beispiel: Eine KI lernt von einem rassischtischen Dokument, dass Dunkelhäutige kriminell sind. Also lernt die KI grob gesagt: Dunkelhäutige Menschen sind immer kriminell. Ich werde diese benachteiligen" Diese KI kann zum Beispiel für das aussortieren von Bewerbern in einem Konzern verantwortlich sein. Das führt dazu, dass er alle dunkelhäutigen Bewerber aussortiert und sie somit diskriminiert werden, aufgrund der minderwertigen Daten von der eine KI gelernt hat. So etwas Ähnliches ist tatsächlich passiert. Dazu steht unter \ref{6.1} mehr. Solche Diskriminierungsfälle sind sehr problematisch, da immer mehr von KI gesteuert wird und sie auch Entscheidungen treffen können und so viele Personen, wenn auch ohne Absicht der Hersteller der KI, benachteiligt werden können. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{KI Diskriminierung 2.jpg}
    \caption{}
\label{fig:Diskriminierung}
\end{figure}

\section{\textit{Auswirkungen der Diskriminierung}}
Auf gesellschaftlicher Ebene kann KI die bestehenden sozialen Ungleichheiten verschärfen. Wenn zum Beispiel eine KI bei der Auswahl von Bewerbern für Jobs bestimmte Gruppen wie Frauen benachteiligt, haben diese schlechtere Chancen in der Arbeiswelt. Dies kann dazu führen, dass die Nachfrage nach Frauen in einem Job weiter verschlechtert wird. Ein weiteres Problem ist, dass das Vertrauen in technologische Fortschritte darunter leiden kann, wenn Menschen merken, dass KI diskriminiert. Dies könnte dazu führen, dass die Anzahl neuer Technologien sinkt und ihr Nutzen nicht voll ausgeschöpft wird, da sie nicht mehr akzeptiert wird. Ausserdem kann diskriminierende KI gesellschaftliche Streitigkeiten erhöhen, da die betroffenen Personengruppen sich unfair behandelt fühlen und das Vertrauen des Konzerns verlieren, die diese Technologien nutzen. Auf individueller Ebene sind die Auswirkungen ebenfalls gravierend. Menschen, die von der Diskriminierung betroffen sind, können in vielen Bereichen ihres Lebens benachteiligt werden. Dies kann bei der Jobsuche, der Wohnungssuche oder dem Zugang zu Krediten der Fall sein. Beispielsweise könnten Frauen oder Menschen aus ethnischen Minderheiten schlechtere Chancen haben, eine Wohnung zu finden, wenn die KI immer die Gleichen benachteiligt. Solche Erfahrungen können auch psychisch belastend sein, da sie das Gefühl von Ungerechtigkeit verstärken. Dies kann das Selbstwertgefühl und das allgemeine Wohlbefinden beeinträchtigen. Zudem werden den betroffenen Menschen oft Chancen genommen, ihr volles Potenzial zu entfalten. Geeignete Personen könnten aufgrund von Vorurteilen der KI übersehen werden, was ihre beruflichen und persönlichen Chancen einschränkt. Zusammengefasst kann man sagen, dass diskriminierende KI sowohl das Leben einzelner Menschen als auch gesellschaftliche Aspekte negativ beeinflusst werden. Daher ist es wichtig, dass Manahmen ergriffen werden, um solche Diskriminierungen zu erkennen, zu verhindern und zu korrigieren. 

\section{\textit{Was kann man gegen die Diskriminierung tun?}}
Zunächst einmal ist es wichtig, dass hochwertige und vielfältige Daten verwendet werden, um die KI zu trainieren. Das bedeutet, dass sichergestellt werden muss, dass die Daten keine rassistischen oder sexistischen Inhalte haben und verschiedene Personengruppen vertreten sind. Wenn eine KI mit voreingenommenen Daten trainiert wird, können sie Vorurteile entwickeln und diskriminierende Entscheidungen treffen. Durch die Verwendung vielfältiger Daten kann sichergestellt werden, dass die KI gerechte und ausgewogene Entscheidungen trifft. Darüber hinaus müssen ethische Richtlinien für den Einsatz von KI entwickelt und eingehalten werden. Diese Richtlinien sollten sicherstellen, dass KI die Menschenrechte respektieren und keine Diskriminierung aufgrund von Merkmalen wie Geschlecht, Hautfarbe oder Religion fördern. Es ist wichtig, dass Entwickler ethische Überlegungen in den gesamten Entwicklungsprozess einbeziehen und sicherstellen, dass sie verantwortungsbewusst eingesetzt werden. Zudem müssen die Daten vorher kontrolliert werden, bevor sie damit eine KI trainieren. Schliesslich ist es wichtig, dass die Entwicklung und der Einsatz von KI immer überwacht und wenn nötig verbessert wird. Durch regelmässige Überprüfungen können entstehende Diskriminierungen frühzeitig erkannt und geeignete Massnahmen ergriffen werden, um sie zu beheben. Es ist auch wichtig, dass die Auswirkungen von KI auf verschiedene Bevölkerungsgruppen untersucht werden und sichergestellt wird, dass sie fair und gerecht eingesetzt wird. "Wenn künstliche Intelligenz Rassismus und Vorurteile verstärkt, fällt das nicht unbedingt allen Menschen und Betroffenen sofort auf. Erkennen Betroffene jedoch, dass sie gerade von einem Algorithmus diskriminiert und ausgegrenzt werden, trauen sich viele nicht, dagegen vorzugehen." So sagt die Website \citep{KI-Rassismus}. Das Zitat zeigt, dass oft nicht das Nötige getan wird, um solche Systeme zu sperren oder zu korrigieren.

\section{\textit{Beispiele}}

\subsection{\textit{Amazon}}\label{6.1}
Amazon wollte eine KI entwickeln, um bei der Auswahl von Bewerbern für offene Stellen zu helfen. Die Idee war, dass die KI die Lebensläufe von Bewerbern durchsieht und entscheidet, welche am Besten geeignet sind. Um der KI beizubringen, welche Bewerber gut sind, fütterte Amazon die KI mit Lebensläufen von Personen, die in der Vergangenheit erfolgreich bei Amazon gearbeitet hatten. Das Problem war, dass in der Vergangenheit mehr Männer als Frauen bei Amazon eingestellt wurden. Die KI lernte also ungewollt, dass männliche Bewerber besser sind, weil die Daten aus der Vergangenheit das so widerspiegelten. Die KI begann dann, Lebensläufe von Frauen schlechter zu bewerten und bevorzugte Lebensläufe, die „männlicher“ aussahen. Zum Beispiel, wenn im Lebenslauf eines Bewerbers das Wort „Frauen“ vorkam, wie bei „Frauenfussballteam“ oder „Frauenstudiengang“, sortierte die KI diesen Lebenslauf aus. Das führte dazu, dass Frauen weniger Chancen hatten, von der KI ausgewählt zu werden. Als Amazon dieses Problem erkannte, wurde entschieden, das System nicht weiter zu nutzen. Dieses Beispiel zeigt, wie eine KI unbeabsichtigt diskriminieren kann, wenn sie aus den falschen Daten lernt. Es zeigt auch, wie wichtig es ist, solche Systeme sorgfältig zu überwachen und sicherzustellen, dass sie fair sind. Mehr zu diesem Beispiel gibt es bei \citep{AmazonAlgorithmus}

\subsection{\textit{Kindergeldskandal}}
2019 gab es in den Niederlanden einen selbsterlernten Algorithmus, welcher zur Erstellung von Risikoprofilen verwendet wurde. Das bedeutet, der Algorithmus suchte nach Familien, welche verdächtigt wurden, dass sie Betrug beim Bezug von Kindergeld begingen. Da der Algorithmus das nicht ganz genau durchführen konnte, wurden unschuldige Familien bestraft und mussten das Kindergeld, welche sie über Jahre lang bekommen hatten, zurückzahlen. Es wurden vor allem Familien mit Migrationshintergrund und niedrigem EInkommen fälschlicherweise verdächtigt. Durch die entstandenen Schulden mussten viele Familien ihre Kinder in Kinderheime geben und wurden in die Armut getrieben. Die Seite \citep{DiskriminierendeAlgorithmen} sagt:"Die Datenschutzbehörde kam zum Schluss, dass die Verarbeitung der Daten durch das eingesetzte System diskriminierend war."

\section{\textit{Fazit}}
Die KI ist noch nicht so ausgereift, wie viele denken. Es gibt überall Fehler und falsche Antworten oder Vorgehen. Fakt ist aber, dass diese immer vom Menschen kommen. Denn die Hersteller, welche die Algorithmen bauen, lassen ihre oder andere Meinungen und Vorurteile in das Training einer KI einfliessen. "Daher besteht die Gefahr, dass die Entwickler*innen bereits bestehende Diskriminierungsmechanismen unserer Gesellschaft in Algorithmen und somit auch in KI übertragen.", sagt die Seite \citep{Digitalisierung}. So kann eine KI schnell diskriminierend werden und einen Menschen ohne Grund benachteiligen. Je nach Diskriminierung, sei es ein Algorithmus, welcher weibliche Bewerberinnen aussortiert, oder eine KI, welche rassischtische Antowrten gibt. Das Ausmass kann verheerend sein. Diskriminierung wird oft nicht entdeckt, wodurch sie noch schädlicher sein kann. Das Problem liegt also nicht nur bei der KI, es liegt in der Gesellschaft und in der Denksweise der Menschen. 

\nocite{*}

\printbibliography

\end{document}
